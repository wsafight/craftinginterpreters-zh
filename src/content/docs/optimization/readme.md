---
title: 30. 优化
description: Optimization
---

> 夜晚是一天中最美好的时光。你已经完成了一天的工作，现在你可以双腿搁平，享受一下。（石黑一雄，《长日将尽》）
>
> ​ ——Kazuo Ishiguro, _The Remains of the Day_

如果我还住在新奥尔良，我会把这一章称为*lagniappe*（小赠品），即免费送给顾客的一点额外的东西。你已经有了一整本书和一个完整的虚拟机，但我希望你能在 clox 上获得更多的乐趣。这一次，我们要追求的是纯粹的性能。我们将对虚拟机应用两种截然不同的优化。在这个过程中，你将了解如何测量和提高语言实现的性能——或者说任何程序的性能，真的。

## 30.1 测量性能

**优化**是指拿到一个基本可用的应用程序并提高其性能。一个优化后的程序能做到同样的事情，只是需要更少的资源。我们在优化时通常考虑的资源是运行时速度，但减少内存使用、启动时间、持久化存储大小或网络带宽也很重要。所有的物理资源都有一定的成本——即使成本主要是浪费人力时间，所以优化工作通常都能得到回报。


在计算机早期，曾经有一段时间，一个熟练的程序员可以把整个硬件架构和编译器管道记在脑子里，只需要认真思考就可以了解程序的性能。那些日子早已一去不复返了，现在已经被微码、缓存线、分支预测、深层编译器管道和庞大的指令集所分隔。我们喜欢假装 C 语言是一种“低级”语言，但在`printf("Hello, world!");`和屏幕上出现的问候语之间的技术栈现在已经很高了。

今天的优化是一门经验科学。我们的程序是一只在硬件障碍赛中冲刺的边牧。如果我们想让她更快地到达终点，我们不能只是坐在那里思考犬类的生理机能，等着灵光乍现。相反，我们需要*观察*她的表现，看看她在那里出错，然后为她找到更快的路径。
就像敏捷训练要真的一只狗和一项障碍赛，我们不能假设我们的虚拟机优化会使所有的 Lox 程序在所有硬件上运行得更快。不同的 Lox 程序侧重虚拟机的不同领域，不同的架构也有其自身的优势和劣势。

### 30.1.1 基准

当我们添加新功能时，我们通过编写测试来验证正确性——使用某个特性并验证虚拟机行为的 Lox 程序。测试可以约束语义，并确保在添加新功能时，不会破坏现有的特性。在性能方面，我们也有类似的需求：

1. 我们如何验证一项优化确实提高了性能，以及提高了多少？
2. 我们如何确保其它不相关的修改不会使性能退步？

我们为实现这些目标而编写的 Lox 程序就是**基准**。这些都是精心设计的程序，侧重于语言实现的某些部分。它们测量的不是程序*做了什么*，而是做完这些需要*多久*[^1]。

通过测量修改前后的基准性能，你可以看到修改的效果。当你完成优化时，所有测试都应该与之前的行为完全一样，只是希望基准程序运行更快一点。

一旦你有了一整套的基准测试，你不仅可以衡量某个优化是否改变了性能，而且可以衡量改变了哪类代码的性能。通常，你会发现一些基准测试变得更快，而另一些则变得更慢。然后你必须作出艰难的决策：你的语言实现要对哪种代码进行优化。

你选择编写的基准套件是该决策的一部分。就像你的测试代码编码了关于正确代码行为的选择，你的基准测试是你在性能方面侧重点的体现。它们将指导你实现哪些优化，所以要仔细选择你的基准测试，并且不要忘记定期反思它们是否能帮助你实现更大的目标[^2]。

基准测试是一门微妙的艺术。就像测试一样，你需要在不过度拟合语言实现的同时，确保基准测试确实适合你所关心的代码路径。在测量性能时，你需要补偿由 CPU 节流、缓存和其它奇怪的硬件和操作系统特性造成的差异。我不会在这里给你一个完整的说教，但请把基准测试当作可以通过实践来提高的一门技能。

### 30.1.2 剖析

好的，现在你已经有了一些基准测试。你想让它们走得更快，现在怎么办呢？首先，我们假设你已经完成了所有明显的、简单的工作。你使用了正确的算法和数据结构——或者，至少你没有使用那些严重错误的算法和数据结构。我认为使用哈希表代替巨大的无序数组进行线性搜索不是“优化”，而是“良好的软件工程实现”。

由于硬件太过复杂，无法从基本原理推断出程序的性能，所以我们必须深入实地。这意味着*剖析*。**剖析器**（如果你从未使用过）是一种工具，可以运行你的程序并在代码执行过程中跟踪硬件资源的使用情况[^3]。简单的剖析器可以向你展示程序中每个函数花费了多少时间。复杂的剖析器则会记录数据缓存缺失、指令缓存缺失、分支预测错误、内存分配和其它各种指标。

现在有很多针对不同操作系统和语言的剖析器。无论你在什么平台上编程，熟悉一个像样的剖析器都是值得的。你不需要称为大师。我在把程序扔给剖析器的几分钟内就学到了很多东西，而这些东西是我自己通过反复试验*好几天*才发现的。剖析器是一种绝妙、神奇的工具。


## 30.2 更快的哈希表探测


废话说得够多了，我们来让性能图表趋向右上方（提升性能）。我们要做的第一个优化，事实证明也是我们可以对虚拟机所做出的最微小的改变。

当我第一次让 clox 派生的字节码虚拟机工作时，我做了任何有自尊心的虚拟机黑客都会做的事情。我拼凑了几个基准测试，启动了一个剖析器，并通过我的解释器运行了这些脚本。在 Lox 这样的动态类型语言中，用户代码的很大一部分是字段访问和方法调用，所以我的其中一个基准测试看起来是这样的[^4]：

```typescript
class Zoo {
  init() {
    this.aardvark = 1;
    this.baboon   = 1;
    this.cat      = 1;
    this.donkey   = 1;
    this.elephant = 1;
    this.fox      = 1;
  }
  ant()    { return this.aardvark; }
  banana() { return this.baboon; }
  tuna()   { return this.cat; }
  hay()    { return this.donkey; }
  grass()  { return this.elephant; }
  mouse()  { return this.fox; }
}

var zoo = Zoo();
var sum = 0;
var start = clock();
while (sum < 100000000) {
  sum = sum + zoo.ant()
            + zoo.banana()
            + zoo.tuna()
            + zoo.hay()
            + zoo.grass()
            + zoo.mouse();
}

print clock() - start;
print sum;
```

如果你以前从未见过基准测试，那这个看起来可能会很好笑。这是怎么回事？这个程序本身并不打算做任何有用的事情。它所做的就是调用一堆方法和访问一堆字段，因为这些是语言中我们感兴趣的部分。字段和方法都在哈希表中，因此需要小心地在这些表中至少填入几个有趣的键[^5]。这一切都包装在一个大循环中，以确保我们的剖析器有足够的执行时间来挖掘和查看循环的走向。

在我告诉你剖析器显示了什么之前，先花点时间猜一下。你认为在 clox 的代码库中，虚拟机的大部分时间都花在了哪里？我们在前几章所写的代码中，有没有你怀疑特别慢的？

下面是我的发现：自然，非独占时间最大的函数是`run()`。（**非独占时间（Inclusive time）**是指在某个函数及其调用的所有其它函数中所花费的总时间——即从你进入函数到函数返回之间的总时间。）因为`run()`是主要的字节码执行循环，它驱动着一切。


在`run()`内部，有小块的时间视不同情况分散在如`OP_POP`、`OP_RETURN`、`OP_ADD`等常见指令中。较大的重磅指令是占执行时间 17%的`OP_GET_GLOBAL`，占 12%的`OP_GET_PROPERTY`，还有占总运行时间的 42%的`OP_INVOKE`。

所以我们有三个热点需要优化？事实上，并不是。因为事实证明，这三条指令几乎所有的时间都花在了调用同一个函数上：`tableGet()`。这个函数占用了整整 72%的执行时间（同样的，非独占时间）。现在，在一个动态类型语言中，我们预想到会花费相当多的时间在哈希表中查找内容——这算是动态的代价，但是，仍旧让人惊叹。

### 30.2.1 缓慢的键包装


如果查看一下`tableGet()`，你会发现它主要是对`findEntry()`调用的一个包装，而`findEntry()`是真正进行哈希表查找的地方。为了唤起你的记忆，下面是它的全部内容：

```c
static Entry* findEntry(Entry* entries, int capacity,
                        ObjString* key) {
  uint32_t index = key->hash % capacity;
  Entry* tombstone = NULL;

  for (;;) {
    Entry* entry = &entries[index];
    if (entry->key == NULL) {
      if (IS_NIL(entry->value)) {
        // Empty entry.
        return tombstone != NULL ? tombstone : entry;
      } else {
        // We found a tombstone.
        if (tombstone == NULL) tombstone = entry;
      }
    } else if (entry->key == key) {
      // We found the key.
      return entry;
    }

    index = (index + 1) % capacity;
  }
}
```


在运行之前的基准测试时——至少在我的机器上是这样——虚拟机将总执行时间的 70%花费在这个函数的*一行*代码上。能猜到是哪一行吗？猜不到？是这一行：

```c
  uint32_t index = key->hash % capacity;
```

问题不在于指针解引用，而是那个小小的`%`。事实证明，取模操作符*真的*很慢。比其它算术运算符慢得多[^6]。我们能做得更好吗？

在一般情况下，要想在用户代码中重新实现一个算术运算符，而且要比 CPU 本身的运算速度更快，这是非常难的。毕竟，我们的 C 代码最终会被编译为 CPU 自己的算术运算。如果有什么技巧可以加速运算，芯片早就在使用了。

然而，我们可以利用这一事实：我们比 CPU 更了解我们的问题。我们在这里使用取模将键字符串的哈希码包装到表的项数组的大小范围内。该数组开始时有 8 个元素，每次增加 2 倍。我们知道（CPU 和 C 编译器都不知道）我们的表大小总是 2 的幂。

因为我们是聪明的位操作者，我们知道一个更快的方法来计算一个数以 2 的幂为模的余数：**位掩码**。假设我们要计算 229 对 64 取模。答案是 37，这在十进制中不是特别明显，但当你用二进制查看这些数字时，就会更清楚：

![The bit patterns resulting from 229 % 64 = 37 and 229 & 63 = 37.](./mask.png)

在图的左侧，注意结果（37）是如何简单地将除数（229）的最高两位削除？这两个最高的位是被除数第一个 1 及其左侧的比特位。


在右边，我们将 299 和 63（原来的 2 的幂除数减一）进行按位与操作，也可以得到同样的结果。2 的幂减去 1 会得到一系列的 1 比特。这正是我们需要的掩码，以便剥离掉最左侧的两个比特。

换句话说，要计算某个数与任何 2 的幂的模数，你可以简单地将该数与 2 的幂减 1 进行位相与。我不是一个数学家，无法向你证明这一点，但如果你仔细想想，这应该是有道理的。我们可以用一个非常快的减法和按位与运算来替换那个缓慢的模运算。我们只是简单地将那行代码改为：

_<u>table.c，在 findEntry()方法中替换 1 行：</u>_

```c
static Entry* findEntry(Entry* entries, int capacity,
                        ObjString* key) {
  // 替换部分开始
  uint32_t index = key->hash & (capacity - 1);
  // 替换部分结束
  Entry* tombstone = NULL;
```

CPU 喜欢位运算，因此很难在此基础上进行改进[^7]。

我们的线性探测搜索可能需要在数组的末尾绕回起点，所以在`findEntry()`中还有一个模运算需要更新。

_<u>table.c，在 findEntry()方法中替换 1 行：</u>_

```c
    // We found the key.
      return entry;
    }
    // 替换部分开始
    index = (index + 1) & (capacity - 1);
    // 替换部分结束
  }
```

这一行没有出现在剖析器中，是因为大部分搜索都不需要绕回。


`findEntry()`函数有一个姊妹函数，`tableFindString()`，它为驻留的字符串做哈希表查询。我们不妨在这里也应用同样的优化。该函数只在对字符串进行驻留时才会被调用，我们的基准测试中没有特别侧重这一点。但是一个创建大量字符串的 Lox 程序可能会从这个调整中明显受益。

_<u>table.c，在 tableFindString()方法中替换 1 行：</u>_

```c
  if (table->count == 0) return NULL;
  // 替换部分开始
  uint32_t index = hash & (table->capacity - 1);
  // 替换部分结束
  for (;;) {
    Entry* entry = &table->entries[index];
```


当线性探索绕回起点时也是如此。

_<u>table.c，在 tableFindString()方法中替换 1 行：</u>_

```c
    return entry->key;
    }
    // 替换部分开始
    index = (index + 1) & (table->capacity - 1);
    // 替换部分结束
  }
```

来看看我们的修补是否值得。我调整了前面的动物学基准测试，计算它能在 10 秒内运行多少批的 10000 次调用[^8]。处理批次越多，性能越快。在我的机器上，使用未优化的代码，基准测试可以执行 3192 个批次。经过优化之后，这个数字跃升到了 6249。

![Bar chart comparing the performance before and after the optimization.](./hash-chart.png)

在同样的时间内，工作量几乎是原来的两倍。我们让虚拟机的速度提高了一倍（警告：在这个基准测试中）。对于优化来说，这是一个巨大的胜利。通常情况下，如果你能在这里或那里提升几个百分点，你都会感觉很好。因为方法、字段和全局变量在 Lox 程序中非常普遍，因此这个微小的优化可以全面提高性能。几乎每个 Lox 程序都会受益。

现在，本节的重点不是说取模运算符非常邪恶，你要把它从你写的每个程序中剔除。也不是说微优化是一项重要的工程技能。很少有一个性能问题具有如此狭窄、有效的解决方案。我们很幸运。

关键在于，直到剖析器告诉我们，我们才知道取模运算符是一个性能损耗。如果我们在虚拟机的代码库中盲目地猜测热点，我们可能不会注意到它。我想让你从中学到的是，在你的工具箱中拥有一个剖析器是多么重要。

为了强化这一点，我们继续在现在已优化的虚拟机中运行最初的基准测试，看看剖析器会显示什么。在我的机器上，`tableGet()`仍然占用了相当大的执行时间。对于动态类型的语言来说，这是可以预期的结果。但是它已经从 72%下降到了 35%。这更符合我们希望看到的情况，表明我们的优化不仅使程序更快，而且是以预期的方式使它更快。剖析器在验证解决方法时和发现问题时一样有用。

## 30.3 NaN 装箱

接下来的这个优化有着非常不同的感觉。值得庆幸的是，虽然它的名字很奇怪，但它并不会推翻一切。确实不同，但不会那么不同。在我们之前的优化中，剖析器会告诉我们问题出在哪里，而我们只需要发挥一些聪明才智就可以想出解决方案。

这个优化更加微妙，它对性能的影响在虚拟机在更加分散。剖析器无法帮我们找到它。相反，它是由一个对机器架构底层进行深入思考的人发明的[^9]。

正如标题所说，这种优化称为**NaN 装箱**，有时也被称为**NaN 标记**。我个人更喜欢后者，因为“装箱”往往意味着某种堆分配的表示形式，但前者似乎是使用广泛的术语。这种技术改变了我们在虚拟机中表示值的方式。

在 64 位机器上，我们的 Value 类型占用了 16 个字节。该结构体中有两个字段，一个类型标签和一个存储有效载荷的联合体。联合体中最大的字段是一个 Obj 指针和一个 double 值，都是 8 字节。为了使联合体字段与 8 字节边界对齐，编译器也在标签后面添加了填充：

![Byte layout of the 16-byte tagged union Value.](./union.png)

真可真够大的。如果我们能把它减少，那虚拟机就能在相同的内存中装入更多的值。现在大多数计算机都有足够的 RAM，所以节省直接内存不是什么大问题。但是更小的表示方式意味着有更多的值可以放入缓存行中。这意味着更少的缓存失误，从而影响*速度*。

既然 Value 需要与最大的有效载荷对齐，而且 Lox 数值或 Obj 指针需要完整的 8 个字节，那我们如何才能变得更小呢？在 Lox 这样的动态类型语言中，每个值不仅需要携带其有效载荷，还需要携带足够多的附加信息，以便在运行时确定值的类型。如果一个 Lox 的数字已经用了整整 8 个字节，那我们可以在哪里偷取两个额外的比特来告诉运行时“这是一个数字”？

这是动态语言黑客长期面临的问题之一。因为静态类型语言通常不存在这个问题，所以这让他们特别困扰。每个值的类型在编译时就已经知道了，所以在运行时不需要额外的内存来记录这些信息。当你的 C 语言编译器编译一个 32 位的 int 时，产生的变量会得到*正好*32 位的存储空间。

动态语言的人讨厌输给静态阵营，所以他们想出了许多非常聪明的方法，将类型信息和有效载荷打包到少量的比特中。NaN 装箱就是其中之一。它特别适合于像 JavaScript 和 Lua 这样的语言，在这些语言中，所有数字都是双精度浮点数。Lox 也是如此。

### 30.3.1 什么是（以及不是）数值？

在开始优化之前，我们需要真正了解我们的朋友 CPU 是如何表示浮点数的。现在几乎所有的机器都使用相同的方案，编码在古老的卷轴[IEEE 754](https://en.wikipedia.org/wiki/IEEE_754)中，凡人们称之为“IEEE 浮点运算标准”。


在你的计算机看来，一个 64 位、双精度的 IEEE 浮点数是这样的：

![Bit representation of an IEEE 754 double.](./double.png)

- 从右边开始，前 52 位是**分数**、**尾数**或**有效位**。它们以二进制整数形式表示数值的有效数字。
- 接下来是 11 个**指数**位。它们会告诉你尾数中的小数点要移动多少位。
- 最高的位是**符号**位，表示这个数值是正数还是负数[^10]。

我知道这有一点模糊，但这一章并不是对浮点数表示法的深入探讨。如果你想知道指数和尾数是如何互相作用的，外面已经有比我写得更好的解释了。

对于我们的目的来说，重要的部分是该规范列出了一个特殊情况下的指数。当指数位全部置为 1，这个值就不再表示一个非常大的数字了，而是有着不同的含义。这些值是“非数字”（Not a Number，即**NaN**）值。它们代表了像无穷或除 0 结果这样的概念。

任何指数位全部被置为 1 的 double 数都是 NaN，无论尾数位是什么。这意味着有很多*不同*的 NaN 模式。IEEE 754 将其分为两类。最高尾数位为 0 的值被称为**信号 NaN**，其它的是**静默 NaN**。信号 NaN 是错误计算的结果，如除以 0。当这些值被生成时，芯片可以检测到并完全中止程序[^11]。如果你试图读取这些值，它们可能会自毁。

静默 NaN 使用起来更安全。它们不代表有用的数值，但它们至少不会一碰就着。

每一个所有指数位置 1、最高尾数位置 1 的 double 都是一个静默 NaN。这就留下了 52 个未解释的位。我们会避开其中一个，这样我们就不会踩到 Intel 的“QNaN 浮点不确定”值，剩下 51 位。这些剩余的比特可以是任何东西。我们现在说的是 2,251,799,813,685,248 独一无二的静默 NaN 位模式。

![The bits in a double that make it a quiet NaN.](./nan.png)

这意味着一个 64 位的 double 有足够的框架存储所有不同的浮点数值，*还*有 52 位的数据空间供我们随意使用。这样就有足够的空间来预留几个位来表示 Lox 的`nil`、`true`和`false`值。但是 Obj 的指针呢？指针不是也需要 64 位吗？


幸运的是，我们还有另一个妙招。是的，从技术上讲，64 位架构上的指针是 64 位的。但是，我所知道的架构中没有一个真正使用了整个地址空间。相反，如今大多数广泛使用的芯片只使用低 48 位[^12]。剩余 16 位要么未指定，要么始终为零。


如果我们有 51 比特位，可以把一个 48 位的指针塞进去，还有 3 比特位的空闲。这三个比特位刚好可以用来存储微小的类型标记来区分`nil`、布尔值和 Obj 指针。


这就是 NaN 装箱。在一个 64 位的 double 中，你可以存储所有不同的浮点数值、一个指针或其它一些特殊的标示值。这比我们当前 Value 结构体少了一半的内存占用量，同时保留了所有的精确性。


这种表示方法的特别之处在于，不需要将数值类型的 double 值*转换*为一个“装箱后的”形式。Lox 中的数字只是普通的 64 位 double。在使用之前，我们仍然需要*检查*它们的类型，因为 Lox 是动态类型的，但我们不需要做任何的数位偏移或指针引用来完成从“值”到“数”的转换。

对于其它的值类型，当然有一个转换步骤。但幸运的是，我们的虚拟机将从值到原始类型的所有机制都隐藏在少数几个宏后面。重写这些宏来实现 NaN 装箱，虚拟机的其它部分就可以正常工作了。

### 30.3.2 有条件地支持

我知道这个新表示形式的细节在你的脑子里还不清晰。不用担心，它们会在我们的实现过程中逐步具现化。在此之前，我们要放置一些编译时的脚手架。

对于我们之前的优化，我们重写之前的慢代码就可以宣告完成了。这一次则有点不同。NaN 装箱依赖于芯片如何表示浮点数和指针等一些非常底层的细节。它也许适用于你可能遇到的大多数 CPU，但你永远无法完全确定。

如果我们的虚拟机仅仅因为某个架构的值表示形式而完全失去对它的支持，那就太糟糕了。为了避免这种情况，我们会保留对 Value 的旧的带标记联合体实现方式以及新的 NaN 装箱形式的支持。我们在编译时使用这个标志来选择我们想要的方法：

_<u>common.h，添加代码：</u>_

```c
#include <stdint.h>
// 新增部分开始
#define NAN_BOXING
// 新增部分结束
#define DEBUG_PRINT_CODE
```

如果定义了这个值，虚拟机就会使用新的形式。否则，它就会恢复旧的风格。少数关心值表示形式细节的几段代码——主要是用于包装和解包 Value 的少数几个宏——会根据这个标志是否被设置而有所不同。虚拟机的其它部分可以继续快乐的旅程。

大部分工作都发生在“value”模块中，我们在其中为新类型添加一些代码。

_<u>value.h，添加代码：</u>_

```c
typedef struct ObjString ObjString;
// 新增部分开始
#ifdef NAN_BOXING

typedef uint64_t Value;

#else
// 新增部分结束
typedef enum {
```

当启用 NaN 装箱时，Value 的实际类型是一个扁平的、无符号的 64 位整数。我们可以用 double 代替，这会使处理 Lox 数字的宏更简单一些。但所有其它宏都需要进行位操作，而 uint_64 是一个更友好的类型。在这个模块之外，虚拟机的其它部分并不真正关心这一点。

在我们开始重新实现这些宏之前，我们先关闭旧表示形式的定义末尾的`#ifdef`的`#else`分支。

_<u>value.h，添加代码：</u>_

```c
#define OBJ_VAL(object)   ((Value){VAL_OBJ, {.obj = (Obj*)object}})
// 新增部分开始
#endif
// 新增部分结束
typedef struct {
```


我们剩下的任务只是在第一个`#ifdef`部分中填入已经在`#else`部分存在的所有内容的新实现。我们会从最简单到最难，依次完成每个值类型的工作。


### 30.3.3 数字


我们会从数字开始，因为它们在 NaN 装箱方式中有最直接的表示形式。要将 C 语言中的 double“转换”为一个 NaN 装箱后的 clox Value，我们不需要改动任何一个比特——其表示方式是完全相同的。但我们确实需要说服我们的 C 编译器相信这一事实，我们将 Value 定义为 uint64_t 使之变得更加困难。


我们需要让编译器接受一组它认为是 double 的比特，并作为 uint64_t 来使用，反之亦然。这就是所谓的**类型双关**。C 和 C++程序员早在喇叭裤和 8 音轨的时代就开始这样做了，但语言规范却一直犹豫不决，不知道哪种方法是官方认可的[^13]。

我知道一种将`double`转换为`Value`并反向转换的方法，我相信 C 和 C++规范都支持该方法。不幸的是，它不适合在一个表达式中使用，因此转换宏必须调用辅助函数。下面是第一个宏：

_<u>value.h，添加代码：</u>_

```c
typedef uint64_t Value;
// 新增部分开始
#define NUMBER_VAL(num) numToValue(num)
// 新增部分结束
#else
```

这个宏会将 double 传递到这里：

_<u>value.h，添加代码：</u>_

```c
#define NUMBER_VAL(num) numToValue(num)
// 新增部分开始
static inline Value numToValue(double num) {
  Value value;
  memcpy(&value, &num, sizeof(double));
  return value;
}
// 新增部分结束
#else
```

我知道，很奇怪，对吗？在不改变值的情况下，将一系列字节视为具有不同类型的方式是`memcpy()`？这看起来慢的可怕：创建一个局部变量；通过系统调用 将其地址传递给操作系统，以复制几个字节；然后返回结果，这个结果与输入的字节完全相同。值得庆幸的是，由于这是类型双关的习惯用法，大部分编译器都能识别这种模式，并完全优化掉`memcpy()`。

“拆包”一个 Lox 数字就是镜像操作。

_<u>value.h，添加代码：</u>_

```c
typedef uint64_t Value;
// 新增部分开始
#define AS_NUMBER(value)    valueToNum(value)
// 新增部分结束
#define NUMBER_VAL(num) numToValue(num)
```

这个宏会调用下面的函数：

_<u>value.h，添加代码：</u>_

```c
#define NUMBER_VAL(num) numToValue(num)
// 新增部分开始
static inline double valueToNum(Value value) {
  double num;
  memcpy(&num, &value, sizeof(Value));
  return num;
}
// 新增部分结束
static inline Value numToValue(double num) {
```

它的工作原理完全一样，只是交换了类型。同样，编译器会消除所有这些。尽管对`memcpy()`的那些调用会消失，我们仍然需要向编译器显示我们正在调用*哪个*`memcpy()`，因此我们也需要引入一下[^14]。

_<u>value.h，添加代码：</u>_

```c
#define clox_value_h
// 新增部分开始
#include <string.h>
// 新增部分结束
#include "common.h"
```

其中是大量的代码，最终除了让 C 语言类型检查器保持沉默之外，什么也没做。对一个 Lox 数字进行运行时类型*测试*就比较有趣了。如果我们拿到的所有比特位正好是一个 double，如何判断它是一个 double 呢？是时候玩一些位操作技巧了。

_<u>value.h，添加代码：</u>_

```c
typedef uint64_t Value;
// 新增部分开始
#define IS_NUMBER(value)    (((value) & QNAN) != QNAN)
// 新增部分结束
#define AS_NUMBER(value)    valueToNum(value)
```

我们知道，每个*不是*数字的 Value 都会使用一个特殊的静默 NaN 表示形式。而且假定我们已经正确地避免了任何有意义的 NaN 表示形式（这些实际上可能是通过对数字进行算术运算产生的）。

如果某个 double 值的 NaN 比特位置为 1，而且静默 NaN 比特位也置为 1，还有一个比特位也被置为 1，那我们就可以非常肯定它是我们为其它类型预留的比特模式之一[^15]。为了验证这一点，我们屏蔽掉除静默 NaN 置为 1 的比特之外的所有其它比特位，如果这些位都被置为 1 了，那它一定是某个其它 Lox 类型的已 NaN 装箱的值。否则，它就是一个数字。

静默 NaN 的比特集合是这样声明的：

_<u>value.h，添加代码：</u>_

```c
#ifdef NAN_BOXING
// 新增部分开始
#define QNAN     ((uint64_t)0x7ffc000000000000)
// 新增部分结束
typedef uint64_t Value;
```

如果 C 支持二进制字面量就好了。但如果你做了转换，你会看到那个值是这样的：

![The quiet NaN bits.](./qnan.png)


这正是所有的指数位，加上静默 NaN 比特位，再加上一个额外的用来规避英特尔值的比特位。

### 30.3.4 Nil、true 和 false


下一个要处理的类型是`nil`。这非常简单，因为只有一个`nil`值，因此我们只需要 1 个比特位模式来表示它。还有另外两个单例值，即两个布尔值，`true`和`false`。这总共需要三种唯一的比特位模式。

两个比特可以得到四种不同的组合，这已经足够了。我们要求将未使用的尾数中的两个最低位作为“类型标签”，以确定我们正面对的是这三个单例值中的哪一个。这三个类型标签定义如下：

_<u>value.h，添加代码：</u>_

```c
#define QNAN     ((uint64_t)0x7ffc000000000000)
// 新增部分开始
#define TAG_NIL   1 // 01.
#define TAG_FALSE 2 // 10.
#define TAG_TRUE  3 // 11.
// 新增部分结束
typedef uint64_t Value;
```

因此，我们的`nil`表示形式的所有比特位就是定义静默 NaN 表示形式所需的所有比特位，以及`nil`类型的标记位：

![The bit representation of the nil value.](./nil.png)

在代码中，我们这样来检查：

_<u>value.h，添加代码：</u>_

```c
#define AS_NUMBER(value)    valueToNum(value)
// 新增部分开始
#define NIL_VAL         ((Value)(uint64_t)(QNAN | TAG_NIL))
// 新增部分结束
#define NUMBER_VAL(num) numToValue(num)
```

我们只是将静默 NaN 比特位与类型标签进行按位或运算，然后做一点强制转换来告诉 C 编译器我们希望这些位表示什么意思。

由于`nil`只有一个比特表示形式，我们可以对 uint64_t 使用等号来判断某个 Value 是否是`nil`。

_<u>value.h，添加代码：</u>_

```c
typedef uint64_t Value;
// 新增部分开始
#define IS_NIL(value)       ((value) == NIL_VAL)
// 新增部分结束
#define IS_NUMBER(value)    (((value) & QNAN) != QNAN)
```

你可以猜到我们如何定义`true`和`false`值。

_<u>value.h，添加代码：</u>_

```c
#define AS_NUMBER(value)    valueToNum(value)
// 新增部分开始
#define FALSE_VAL       ((Value)(uint64_t)(QNAN | TAG_FALSE))
#define TRUE_VAL        ((Value)(uint64_t)(QNAN | TAG_TRUE))
// 新增部分结束
#define NIL_VAL         ((Value)(uint64_t)(QNAN | TAG_NIL))
```

比特位看起来是这样的：

![The bit representation of the true and false values.](./bools.png)

为了将 C 语言 bool 转换为 Lox 的 Boolean，我们依靠这两个单例值和古老的条件运算符。

_<u>value.h，添加代码：</u>_

```c
#define AS_NUMBER(value)    valueToNum(value)
// 新增部分开始
#define BOOL_VAL(b)     ((b) ? TRUE_VAL : FALSE_VAL)
// 新增部分结束
#define FALSE_VAL       ((Value)(uint64_t)(QNAN | TAG_FALSE))
```

可能有更聪明的位运算方式来实现这一点，但我的直觉是，编译器可以比我更快地找到一个方法。反过来就简单多了。

_<u>value.h，添加代码：</u>_

```c
#define IS_NUMBER(value)    (((value) & QNAN) != QNAN)
// 新增部分开始
#define AS_BOOL(value)      ((value) == TRUE_VAL)
// 新增部分结束
#define AS_NUMBER(value)    valueToNum(value)
```

因为我们知道在 Lox 中正好有两个 Boolean 的位表示形式——不像 C 语言中，任何非零值都可以被认为是“true”——如果它不是`true`，就一定是`false`。这个宏假设你只会在明知是 Lox 布尔值类型的 Value 上调用该方法。为了检查这一点，还有一个宏。

_<u>value.h，添加代码：</u>_

```c
typedef uint64_t Value;
// 新增部分开始
#define IS_BOOL(value)      (((value) | 1) == TRUE_VAL)
// 新增部分结束
#define IS_NIL(value)       ((value) == NIL_VAL)
```

这里看起来有点奇怪。一个更直观的宏看起来应该是这样的：

```c
#define IS_BOOL(v) ((v) == TRUE_VAL || (v) == FALSE_VAL)
```

不幸的是，这并不安全。展开式中两次使用了`v`，这意味着如果表达式有任何副作用，它们将被执行两次。我们可以让宏调用到一个单独的函数，但是，唉，真麻烦。


相反，我们在值上按位或 1，来合并仅有的两个有效的 Boolean 比特位模式。这样，值就剩下了三种可能的状态：

1. 之前是`FALSE_VAL`，现在转换为`TRUE_VAL`。
2. 之前是`TRUE_VAL`，`| 1`没有起任何作用，结果仍然是`TRUE_VAL`。
3. 它是其它的非布尔值。


在此基础上，我们可以简单地将结果与`TRUE_VAL`进行比较，看看我们是处于前两个状态还是第三个状态。

### 30.3.5 对象


最后一种值类型是最难的。与单例值不同，我们需要在 NaN 中包含数十亿个不同的指针值。这意味着我们既需要某种标签来表明这些特定的 NaN*是*Obj 指针，也需要为这些地址本身留出空间。

我们用于单例值的标签比特位处于我决定存储指针本身的区域，所以我们不能轻易地在那里使用不同的位来表明该值是一个对象引用[^16]。不过，还有一个位我们没有用到。因为所有的 NaN 值都不是数字——正如其名——符号位没有任何用途。我们会继续使用它来作为对象的类型标签。如果某个静默 NaN 的符号位被置为 1，那么它就是一个 Obj 指针。否则，它一定是前面的单例值之一。

如果符号位被置 1，那么剩余的低比特位会存储 Obj 指针：

![Bit representation of an Obj* stored in a Value.](./obj.png)

为了将一个原生 Obj 指针转换为 Value，我们会接受指针并将所有的静默 NaN 比特位和符号位置 1。

_<u>value.h，添加代码：</u>_

```c
#define NUMBER_VAL(num) numToValue(num)
// 新增部分开始
#define OBJ_VAL(obj) \
    (Value)(SIGN_BIT | QNAN | (uint64_t)(uintptr_t)(obj))
// 新增部分结束
static inline double valueToNum(Value value) {
```

指针本身是一个完整的 64 位，原则上，它可能因此与某些静默 NaN 和符号位冲突。但实际上，至少在我测试过的架构中，指针中 48 位以上的所有内容都是零。这里进行了大量的类型转换。我们发现这对于满足一些最挑剔的 C 语言编译器来说是必要的，但最终的结果只是将这些比特位塞在一起[^17]。



我们这样定义符号位：

_<u>value.h，添加代码：</u>_

```c
#ifdef NAN_BOXING
// 新增部分开始
#define SIGN_BIT ((uint64_t)0x8000000000000000)
// 新增部分结束
#define QNAN     ((uint64_t)0x7ffc000000000000)
```



为了取出 Obj 指针，我们只需把所有这些额外的比特位屏蔽掉。

_<u>value.h，添加代码：</u>_

```c
#define AS_NUMBER(value)    valueToNum(value)
// 新增部分开始
#define AS_OBJ(value) \
    ((Obj*)(uintptr_t)((value) & ~(SIGN_BIT | QNAN)))
// 新增部分结束
#define BOOL_VAL(b)     ((b) ? TRUE_VAL : FALSE_VAL)
```



如果你没有做过足够多的位运算就可能没有遇到过，波浪号（`~`）是位运算中的 NOT（按位取非）。它会切换操作数中所有的 1 和 0。使用静默 NaN 和符号位按位取非的值作为掩码，对值进行屏蔽，我们可以*清除*这些比特位，并将指针比特保留下来。



最后一个宏：

_<u>value.h，添加代码：</u>_

```c
#define IS_NUMBER(value)    (((value) & QNAN) != QNAN)
// 新增部分开始
#define IS_OBJ(value) \
    (((value) & (QNAN | SIGN_BIT)) == (QNAN | SIGN_BIT))
// 新增部分结束
#define AS_BOOL(value)      ((value) == TRUE_VAL)
```



存储 Obj 指针的 Value 的符号位被置 1，但任意负数也是如此。为了判断 Value 是否为 Obj 指针，我们需要同时检查符号位和所有的静默 NaN 比特位。这与我们检测单例值类型的方法类似，这不过这次我们使用符号位作为标签。



### 30.3.6 Value 函数



VM 的其余部分在处理 Value 时通常都是通过宏，所以我们基本上已经完成了。但是，在“value”模块中，有几个函数会窥探 Value 黑匣子内部，并直接处理器编码。我们也需要修复这些问题。



第一个是`printValue()`。它针对每个值类型都有单独的代码。我们不再有一个明确的类型枚举进行 switch，因此我们使用一系列的类型检查来处理每一种值。

_<u>value.c，在 printValue()方法中添加代码：</u>_

```c
void printValue(Value value) {
// 新增部分开始
#ifdef NAN_BOXING
  if (IS_BOOL(value)) {
    printf(AS_BOOL(value) ? "true" : "false");
  } else if (IS_NIL(value)) {
    printf("nil");
  } else if (IS_NUMBER(value)) {
    printf("%g", AS_NUMBER(value));
  } else if (IS_OBJ(value)) {
    printObject(value);
  }
#else
// 新增部分结束
  switch (value.type) {
```



从技术上讲，这比 switch 语句稍微慢一点点，但是与实际写入流的开销相比，它可以忽略不计。



我们仍然支持原先的带标签联合体表示形式，因此我们保留旧代码，并将其包含在`#else`条件部分。

_<u>value.c，在 printValue()方法中添加代码：</u>_

```c
  }
// 新增部分开始
#endif
// 新增部分结束
}
```



另一个操作是测试两个值是否相等。

_<u>value.c，在 valuesEqual()方法中添加代码：</u>_

```c
bool valuesEqual(Value a, Value b) {
// 新增部分开始
#ifdef NAN_BOXING
  return a == b;
#else
// 新增部分结束
  if (a.type != b.type) return false;
```



没有比这更简单的了！如果两个比特表示形式是相同的，则值就是相等的。这对于单例值来说是正确的，因为每个单例值都有唯一的位表示形式，而且它们只等于自己。对于 Obj 指针，它也做了正确的事情，因为对象使用本体来判断相等——只有当两个 Obj 指向完全相同的对象时，它们才相等。



对于数字来说，也*基本*是正确的。大多数具有不同位表示形式的浮点数是不同的数值。然而，IEEE 754 中有一个坑，会让我们陷入困境。由于我不太清楚的原因，该规范规定 NaN 值*不*等于*自身*。对于我们自己使用的特殊的静默 NaN 来说，这不是问题。但是在 Lox 中产生一个“真正的”算术型 NaN 是有可能的，如果我们想正确地实现 IEEE 754 数字，那么产生的结果值就不等于它自身。更具体地说：

```typescript
var nan = 0/0;
print nan == nan;
```



IEEE 754 表明，这个程序应该打印“false”。对于我们原先的带标签联合体表示形式来说，它是正确的，因为`VAL_NUMBER`将`==`应用于两个 C 编译器知道是 double 的值。因此，编译器会生成正确的 CPU 指令来执行 IEEE 浮点运算。



我们的新表示形式由于将 Value 定义为 uint64_t 而打破了这一点。如果我们想完全符合 IEEE 754 的要求，就需要处理这种情况。

_<u>value.c，在 valuesEqual()方法中添加代码：</u>_

```c
#ifdef NAN_BOXING
  // 新增部分开始
  if (IS_NUMBER(a) && IS_NUMBER(b)) {
    return AS_NUMBER(a) == AS_NUMBER(b);
  }
  // 新增部分结束
  return a == b;
```



我知道，这很奇怪。而且每次我们检查两个 Lox 值是否相等时，都要进行这种类型测试，这是有性能代价的。如果我们愿意牺牲一点兼容性——谁会*真正*关心 NaN 是否等于其本身呢？——我们可以忽略它。我把这个问题留给你，看看你想要有多“迂腐”[^18]。



最后，我们关闭旧实现中的条件编译部分。

_<u>value.c，在 valuesEqual()方法中添加代码：</u>_

```c
  }
// 新增部分开始
#endif
// 新增部分结束
}
```



就是这样。这个优化完成了，我们的 clox 虚拟机也完成了。这是本书中最后一行新代码。



### 30.3.7 评估性能



代码完成了，但我们仍然需要弄清楚，我们是否真的通过这些修改获得了一些改进。评估这样的优化与之前的优化有很大不同。之前，我们可以在剖析器中看到一个明显的热点。我们修复了这部分代码，并立即看到热点部分变快了。



改变值表示形式的影响更加分散。在宏的任何地方都会进行对应的扩展，所以性能的变化会分散到整个代码库中，这对很多剖析器来说是很难跟踪的，尤其是在优化的构建中[^19]。



我们也无法轻易推断出我们的改变所带来的影响。我们让 Value 变得更小，这就减少了虚拟机中的缓存丢失。但是，这一改变在真实世界中的实际性能影响在很大程序上取决于正在运行的 Lox 程序的内存使用情况。一个很小的 Lox 微基准测试可能没有足够的值分散在内存中，因此效果也许不明显，甚至类似 C 语言地址分配器为我们提供的地址这样的东西也会影响结果。



如果我们的工作做对了，基本上所有东西都会变快一点，尤其是在更大、更复杂的 Lox 程序上。但是，我们对 NaN 装箱值执行的位操作可能会抵消更高效的内存使用所带来的收益。做这样的性能工作是令人不安的，因为你无法轻易地证明你已经使虚拟机变得更好了。你不能指着一个特定的微基准测试说：“看到了吗？”



相反，我们真正需要的是一套更大的基准测试。理想情况下，这些基准测试应该是从真实世界的应用程序中提炼出来的——对于 Lox 这样的玩具语言来说，不存在这样的东西。然后我们可以测量所有这些测试的总体性能变化。我尽力拼凑了几个较大的 Lox 程序。在我的机器是，新的值表示形式似乎使所有的代码都全面提高了大约 10%。



这并不是一个巨大的改进，尤其是与哈希查找加速的深远影响相比。我添加这个优化，很大程度上是因为它是关于你可能遇到的*某种*性能工作的一个很好的例子，而且说实话，我认为它在技术上真的很酷。如果我真的想让 clox 变得更快的话，这应该不是我首先要做的事情。可能还有其它更容易实现的目标。



但是，如果你发现自己正在处理的程序中，所有容易赢得的东西都已经被拿走了，那么在某些时候，你可能要考虑调整一下值表示形式。我希望这一章能对你在这方面的一些选择有所启发。



## 30.4 前路何方



关于 Lox 语言和我们的两个解释器，就到此为止了。我们可以一直对它进行修补，添加新的语言功能和巧妙的速度改进。但是，对于本书来说，我认为我们已经达到了一个可以宣告工作完成的状态。我不会重述我们在过去的许多章节中所学到的一切。你和我一起从那里过来，你都记得。相反，我想花点时间谈谈你今后的发展方向。你的编程语言之旅的下一步是什么？



你们中的大多数人可能不会把职业生涯的大部分时间花在编译器或解释器上。这在计算机科学学术界中的一个相当小的部分，在工业软件工程中则是一个更小的部分。这也没关系。即使你一生中不再从事编译器工作，你也一定会使用它，而我希望这本书能让你更好地理解你所使用的编程语言是如何设计与实现的。



你还学习了一些重要的、基本的数据结构，并进行了一些底层剖析和优化工作的实践。无论你在哪个领域编程，这种专业知识都是有帮助的。



我也希望我为你们提供了一种看待问题和解决问题的新方法。即使你不再从事语言工作，你也可能会惊讶地发现，有多少编程问题可以被视为*类似于*语言的问题[^20]。也许你需要编写的报告生成器可以被建模为一系列由生成器“执行”的、基于堆栈的“指令”。你需要渲染的用户界面看起来非常像遍历 AST。



如果你确实想在编程语言领域中走得更远，这里有一些关于哪些方面可以探索的建议：

- 我们这个简单的、单遍字节码编译器将我们推向了运行时优化。在一个成熟的语言实现中，编译时优化通常更重要，而且编译器优化的领域也非常丰富。找一本经典的编译器书籍[^21]，将 clox 或 jlox 的前端重构为一个复杂的编译管道，其中要包含一些有趣的中间表示形式和优化遍历。

  动态类型会对你能走多远加以限制，但你仍然可以做很多事情。或者你想要来个大跃进，给 Lox 添加静态类型和类型检查器。这肯定会让你的前端有更多的东西可以细细咀嚼。

- 在本书中，我的目标是正确，但不是特别严谨。我的目标主要是给你一个*直观感受*和做语言工作的感觉。如果你想要更精确的感觉，那么整个编程语言学术界都在等着你。在我们拥有计算机之前，语言和编译器就已经被正式研究过了，因此在解析器理论、类型系统、语义学和形式逻辑方面并不缺乏书籍和论文。沿着这条路走下去也会教你如何阅读 CS 论文，这本身就是一项有价值的技能。

- 或者，如果你真的喜欢钻研和制造语言，你可以把 Lox 变成你自己的玩物。把语法改成能让你满意的东西。增加缺失的功能或删除你不喜欢的功能。在其中添加新的优化[^22]。

  最终，你会达到某个境地，有了一些你认为其他人也可以使用的东西。这会带你进入非常独特的编程语言*流行度*的世界。预计你将花费大量的时间来编写文档、示例程序、工具和有用的库。这个领域充斥着很多争夺用户的语言。要想在这个领域取得成功，你将必须带上营销的帽子，进行销售。不是每个人都喜欢这种面对公众的工作，但如果你喜欢，能够看到人们使用你的语言来表达自己，你会感到无比欣慰。


或者，也许这本书已经满足了你的需求，你会在这里停下来。无论你走哪条路，或者不走哪条路，我都希望能把这个教训留在你心里。像我一样，你可能一开始就被编程语言吓到了。但在这些章节中，你已经看到，即使是真正具有挑战性的事情，只要亲自动手，一步一步来，我们这些凡人也可以解决。如果你能处理好编译器和解释器，你就可以做到任何你想做的事情。

[^1]: 大多数基准程序测量的是运行时间。但是，当然，你最终会发现自己需要编写基准测试来测量内存分配、垃圾回收器花费的时间、启动时间等等。
[^2]: 在 JavaScript 虚拟机的早期扩散中，第一个广泛使用的基准测试套件是 WebKit 的 SunSpider。在浏览器大战期间，营销人员利用 SunSpider 的结果来宣称他们的浏览器是最快的。这极大地激励了虚拟机专家们根据这些基准进行优化。<BR>不幸的是，SunSpider 程序往往与真实世界的 JavaScript 不匹配。它们大多是微基准测试——快速结束的小玩具程序。这些基准测试对复杂的即时编译器不利，因为它们一开始速度比较慢，但一旦 JIT 有足够的时间来优化并重新编译热点代码，就会变得快很多。这将虚拟机专家们置于一个不幸的境地：要么让 SubSpider 的数字变得更好，要么实际优化真实用户运行的程序类型。<BR>谷歌的 V8 团队分享了他们的 Octane 基准测试套件，这在当时更接近于真实世界的代码。多年以后，随着 JavaScript 使用模式的不断发展，甚至 Octane 也失去了作用。期待你的基准测试随着你的语言生态系统的发展而发展。<BR>记住，最终目标是使*用户程序*更快，而基准测试只是实现这个目标的一个代替物。
[^3]: 这里的“你的程序”是指运行其它 Lox 程序的 Lox 虚拟机本身。我们要优化的是 clox，而不是用户的 Lox 脚本。当然，选择哪一个 Lox 程序加载到虚拟机中会极大地影响 clox 的哪些部分会受到压力，这就是基准测试如此重要的原因。<BR>剖析器不会告诉我们正在运行的脚本中每个 Lox 函数花费了多少时间。我们必须编写自己的“Lox 剖析器”才能做到这一点，这有点超出了本书的范围。
[^4]: 这个基准测试的另一个注意点是要*使用*所执行的代码的结果。通过计算滚动求和与打印结果，我们确保虚拟机*必须*执行所有的 Lox 代码。这是一个重要的习惯。与我们这个简单的 Lox 虚拟机不同，很多编译器都做了积极的死码消除，并且聪明到会丢弃那些结果未被使用的计算逻辑。<BR>许多编程语言黑客都会对虚拟机在某些基准测试上的惊人表现印象深刻，最后才意识到这是因为编译器将整个基准测试程序优化到不存在了。
[^5]: 如果你真的想要对哈希表的性能进行基准测试，那你应该使用许多不同大小的表。我们在这里给每个表添加的 6 个键甚至都没有超过哈希表中 8 个元素的最小阈值。但我不想向你抛出一个庞大的基准测试脚本。如果你喜欢，可以随意添加更多的小动物和食物。
[^6]: 流水线使得我们很难讨论单个 CPU 指令的性能，但可以给你一个直观感受，在 x86 上，除法和模运算比加法和减法运算慢 30-50*倍*。
[^7]: 另一个潜在的改进是通过直接存储位掩码而不是存储容量值来消除减法。在我的测试中，这并没有什么区别。如果 CPU 在其它方面遇到瓶颈，指令流水线的存在使得一些操作基本上是无用的。
[^8]: 我们最初的基准测试是固定工作量，然后测量时间。修改后的脚本计算它在 10 秒内可以执行多少批次的调用，是固定时间并测量工作量。对于性能的比较，我喜欢后一种方法，因为报告的数字代表了速度。你可以直接比较优化前后的数字。当测量执行时间时，你必须进行一些计算，才能得到一个良好的相对性能测量。
[^9]: 我不确定是谁首先提出了这个技巧。我能找到的最早的资料是 David Gudeman 在 1993 年发表的论文 《在动态类型语言中表示类型信息（Representing Type Information in Dynamically Typed Languages）》。其他人都在引用这篇文章。但是 Gudeman 自己说这篇论文并不是什么新颖的工作，而是 "收集了大量的民间传说"。<BR>也许发明者已经消失在时间的迷雾中，也许它已经被重新发明了很多次。任何人对 IEEE 754 进行了足够长时间的思考，都可能会开始考虑在那些未使用的 NaN 中加入一些有用的信息。
[^10]: 因为符号位一直存在，即使数字是零，这意味着“正零”和“负零”有不同的位表示形式，事实上，IEEE 754 确实区分了它们。
[^11]: 我不知道是否有 CPU 真正做到了捕获信号 NaN 并中止，规范中只是说它们*可以*。
[^12]: 48 比特位足以对 262,114GB 的内存进行寻找。现代操作系统也为每个进程提供了自己的地址空间，所以这应该足够了。
[^13]: 规范的作者不喜欢类型双关，因为它使得优化变得更加困难。一个关键的优化技术是对指令进行重新排序，以填充 CPU 的执行管道。显然，编译器只有在重排序不会产生用户可见的影响时才可以这样做。<BR>指针使得这一点更加困难。如果两个指针指向同一个值，那么通过一个指针进行的写操作和通过另一个指针进行的读操作就不能被重新排序。但是，如果是两个*不同*类型的指针呢？如果这些指针可以指向同一个对象，那么基本上*任意*两个指针都可以成为同一个值的别名。这极大地限制了编译器可以自由地重新排列的代码量。<BR>为了避免这种情况，编译器希望采用**严格别名**——不兼容类型的指针不能指向相同的值。类型双关，从本质上来说，打破了这种假设。
[^14]: 如果你发现自己的编译器没有对`memcpy()`进行优化，可以试试这个：![image-20221111164521148](./image-20221111164521148.png)
[^15]: 非常肯定，但不是严格保证。据我所知，没有什么可以阻止 CPU 产生一个 NaN 值，作为某些操作的结果，而且这些操作的位表示形式会与我们声明的位表示形式相冲突。但在我跨多个架构的测试中，还没有看到这种情况发生。
[^16]: 实际上，即使该值是一个 Obj 指针，我们也*可以*使用最低位来存储类型标签。这是因为 Obj 指针总是被对齐到 8 字节边界，因为 Obj 包含一个 64 位的字段。这反过来意味着 Obj 指针的最低三位始终是 0。我们可以在其中存储任何我们想要的东西，只是在解引用指针之前要将这些屏蔽掉。<BR>这是另一种被称为**指针标记**的值表示形式优化方案。
[^17]: 在涉及到本书中的代码时，我都试图遵循法律条文，所以这一段是值得怀疑的。在优化的时候，你会遇到一个问题，那就是你不仅要突破*规范所规定*的边界，还有突破真正的编译器和芯片所允许的边界。<BR>超出规范之外是有风险的，但在这个无法无天的领域也会有回报。这样做是否值得，取决于你自己。
[^18]: 事实上，jlox 把 NaN 相等性搞错了。当你使用`==`来比较基本类型 double 时，Java 做的是正确的，但如果你把这些值包装在 Double 或 Object 中，并使用`equals()`来比较它们时，就是错的，而这正是 jlox 中使用相等性的方式。
[^19]: 在做剖析工作时，你基本总是想剖析程序的优化后的“发布”构建版本，因为这反映了最终用户体验的性能情况。编译器的优化（如内联）会极大地影响代码中哪些部分是性能热点。手工优化一个调试构建版本，可能会让你去“修复”那些优化编译器本来就会为你解决的问题。<BR>请确保你不会意外地对调试构建版本进行基准测试和优化。我似乎每年都至少要犯一次这样的错误。
[^20]: 这也适用于其它领域。我认为我在编程中所学到的任何一个主题——甚至在编程之外——最终都发现在其它领域中是有用的。我最喜欢软件工程的一个方面正是它对那些兴趣广泛的人的助益。
[^21]: 在这方面，我喜欢 Cooper 和 Torczon 的《_编译器工程，Engineering a Compiler_》。Appel 的《_现代编译器实现，Modern Compiler Implementation_》一书也广受好评。
[^22]: 本书的文本版权归我所有，但 jlox 和 clox 的代码和实现采用了非常宽松的[MIT 许可](https://en.wikipedia.org/wiki/MIT_License)。我非常欢迎你使用[这些解释器](https://github.com/munificent/craftinginterpreters)中的任何一个，对它们做任何你想做的事。去吧。<BR>如果你对语言做了重大改动，最好也能改一下名字，主要是为了避免人们对“Lox”这个名字的含义感到困惑。

---

## 习题

> Assigning homework on the last day of school seems cruel but if you really want something to do during your summer vacation:

在学校的最后一天布置家庭作业似乎很残酷，但如果你真的想在暑假做点什么的话：

1. > Fire up your profiler, run a couple of benchmarks, and look for other hotspots in the VM. Do you see anything in the runtime that you can improve?

   启动你的剖析器，运行几个基准测试，并查找虚拟机中的其它热点。你在运行时中看到什么可以改进的地方吗？

2. > Many strings in real-world user programs are small, often only a character or two. This is less of a concern in clox because we intern strings, but most VMs don’t. For those that don’t, heap allocating a tiny character array for each of those little strings and then representing the value as a pointer to that array is wasteful. Often, the pointer is larger than the string’s characters. A classic trick is to have a separate value representation for small strings that stores the characters inline in the value.
   >
   > Starting from clox’s original tagged union representation, implement that optimization. Write a couple of relevant benchmarks and see if it helps.

   在现实世界的用户程序中，许多字符串都很小，通常只有一两个字符。这种 clox 中不太需要考虑，因为我们会驻留字符串，但大树下虚拟机不会这样做。对于那些不这样做的虚拟机来说，为每个小字符串在堆上分配一个很小的字符数组，然后用一个指向该数组的指针来表示该值是很浪费的。通常情况下，这个指针要比字符串的字符大。一个经典的技巧是为小字符串设置一个单独的值表示形式，该形式会将字符内联存储在值中。

   从 clox 最初的带标签联合体表示形式开始，实现这一优化。写几个相关的基准测试，看看是否有帮助。

3. > Reflect back on your experience with this book. What parts of it worked well for you? What didn’t? Was it easier for you to learn bottom-up or top-down? Did the illustrations help or distract? Did the analogies clarify or confuse?
   >
   > The more you understand your personal learning style, the more effectively you can upload knowledge into your head. You can specifically target material that teaches you the way you learn best.

   回顾一下你在这本书中的经历。哪些部分对你来说很有用？哪些没有？对你来说，自下而上的学习更容易，还是自上而下的学习更简单？插图有帮助还是分散了注意力？类比是澄清了还是混淆了？

   你越了解你的个人学习风格，你就能越有效地将知识输入你的大脑中。你可以有针对性地选择用你最擅长的方式进行教学的材料。
